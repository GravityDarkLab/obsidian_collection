
The security of SMC protocols is typically analyzed under different adversary models, which define the capabilities and objectives of potential attackers.

## Adversary behaviour
### 1. Semi-honest (or Passive)
- **Behavior**: Semi-honest adversaries follow the protocol instructions correctly but are curious. They attempt to learn additional information from the protocol execution beyond their legitimate output.
- **Assumption**: They do not deviate from the predefined protocol steps but will try to glean as much information as possible from the received messages.
- **Protection**: Protocols designed to be secure against semi-honest adversaries aim to ensure that participants cannot learn anything beyond their own input and output, despite potentially analyzing the protocol's transcript.

### 2. Malicious (or Active)
- **Behavior**: Malicious adversaries can deviate from the protocol in any way to either learn other parties' inputs or disrupt the computation. This includes sending incorrect or malformed messages.
- **Assumption**: They may ignore protocol specifications entirely, fabricate messages, or collaborate with other malicious parties to undermine the protocol's integrity or confidentiality.
- **Protection**: Security against malicious adversaries requires mechanisms like zero-knowledge proofs to ensure that all parties adhere to the protocol, without revealing any additional information. These protocols are typically more complex and computationally intensive.

### 3. Covert Adversary
- **Behavior**: Covert adversaries may deviate from the protocol but are deterred by the risk of being caught. This model assumes that adversaries do not want to risk detection and potential penalties.
- **Assumption**: They might cheat if they believe the benefit outweighs the risk of getting caught, but they will not take actions that guarantee detection.
- **Protection**: Protocols designed for this model include mechanisms to detect cheating with a certain probability, thereby discouraging deviations by making them risky for the adversary.

## Adversary threshold structure
### 1. **Honest Majority Setting**: 

The adversary controls a minority of all computing parties
### 2. Dishonest Majority setting:

The adversary controls up to $n-1$ of $n$ computing parties
 
## Adversarial power
### 1. Polynomial-time:

Computational security
### 2. Computationally unbounded:

Information-theoretic security 
 
## Corruption strategy
### 1. Static:

The set of corrupted parties is fixed before the execution begins.
### 2. Adaptive:

The adversary can corrupt parties during the execution, based on what has happened.


## Information-Theoretically Secure Protocols

> A cryptosystem is considered to have information-theoretic security (also called unconditional security) if the system is secure against adversaries with unlimited computing resources and time.